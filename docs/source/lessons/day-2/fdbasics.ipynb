{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Introduction to finite differences\n",
    "\n",
    "## Basic concept\n",
    "\n",
    "The method of finite differences is used, as the name suggests, to transform infinitesimally small differences of variables in differential equations to small but finite differences. This enables solution of these equations by means of numerical calculations in a computer. This might be necessary if the equations at hand are too complicated to be solved analytically, or if the geometry of the problem is too complex.\n",
    "\n",
    "The starting point for the finite differences method is the definition of a derivative:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  \\frac{\\mathrm{d}f}{\\mathrm{d}x}\\Big\\rvert_{x=x_0} = \\lim_{\\Delta x \\rightarrow 0} \\frac{f(x_0 + \\Delta x) - f(x_0)}{\\Delta x}\n",
    "  = \\lim_{\\Delta x \\rightarrow 0} \\frac{f(x_0) - f(x_0 - \\Delta x)}{\\Delta x}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "However, computers can only handle numbers of finite value, not infinitesimally small values such as $\\Delta x$ at the limit used in the definition. Thus, the derivative is approximated by dropping out the limit:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  \\frac{\\mathrm{d}f}{\\mathrm{d}x}\\Big\\rvert_{x=x_0} \\approx \\frac{f(x_0 + \\Delta x) - f(x_0)}{\\Delta x}\n",
    "\\approx \\frac{f(x_0) - f(x_0 - \\Delta x)}{\\Delta x}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $\\Delta x$ is *sufficiently small*. If we could choose arbitrarily small values of $\\Delta x$, we would reach the exact value of the derivative, but in reality we are always limited by the numerical accuracy of the computer, which we will calculate below.\n",
    "\n",
    "Looking at the two finite difference examples above, the first approximation above is called the *forward difference* and the second is the *backward difference*. One can define also the *central difference* approximation:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  \\frac{\\mathrm{d}f}{\\mathrm{d}x}\\Big\\rvert_{x=x_0} \\approx \\frac{ f(x_0 + \\Delta x) - f(x_0 - \\Delta x)}{2\\Delta x}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Other approximations exist, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the computer's numerical accuracy\n",
    "\n",
    "So, how well can a computer store small numbers? One way to assess this is to create a loop that adds increasingly small numbers to the number 1 and then reports the point at which adding the small number does not increase the sum. An example can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "while (1 + 2**(-n) != 1):\n",
    "    n = n + 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taylor series approach and accuracy\n",
    "\n",
    "Taylor's Theorem states that a function $f$ can be represented with the following series in the vicinity of $a$:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  f(x) = f(a) + \\frac{df}{dx}\\frac{(x-a)}{1!} + \\frac{d^2f}{dx^2}\\frac{(x-a)^2}{2!} + \\frac{d^3f}{dx^3}\\frac{(x-a)^3}{3!} + \\ldots\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The finite differences approximation is based on truncating the series, typically after the second term, leading to \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  \\frac{f(x) - f(a)}{x-a} = \\frac{df}{dx} + \\mathcal{O}((x-a)^2)\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$\\mathcal{O}$ represents the *truncation error*, and shows that if $x-a$ (i.e. $\\Delta x$) is halved, the error is dropped to one-fourth. This applies to central difference. Forward and backward differences are *first-order accurate*.\n",
    "\n",
    "## Approximating derivatives\n",
    "\n",
    "Let's define a known function $f(x)=\\sin(2x)+2\\cos(x)$ and plot it on range $x=[-2,2]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.sin(2 * x) + 2 * np.cos(x)\n",
    "\n",
    "x = np.linspace(-2, 2, 100)\n",
    "\n",
    "plt.plot(x, f(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From math we know that $\\frac{df}{dx} = 2\\cos(2x) - 2\\sin(x)$. Let's now define this as a Python function and plot it, together with $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Calculating a derivative function\n",
    "\n",
    " - Define a function `dfdx` that returns the analytically calculated derivative of $f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define function `dfdx` here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-2, 2, 100)\n",
    "\n",
    "plt.plot(x, f(x), label='f')\n",
    "plt.plot(x, dfdx(x), label='df/dx')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate $\\frac{df}{dx}$ numerically, using finite differences, we can define a function that computes the derivative of a given function $g$ at given position $x_0$, using *step size* $dx$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfdx_fd(g, x0, dx):\n",
    "    return (g(x0+dx)-g(x0))/dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this on top of the analytical solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "plt.plot(x, f(x), label='f')\n",
    "plt.plot(x, dfdx(x), label='dfdx')\n",
    "plt.plot(x, dfdx_fd(f, x, 0.3), '.-', label='dfdx_fd')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Changing the spatial difference\n",
    "\n",
    " - Vary the third parameter `dx` of the previous plot. Change it from 0.3 to larger and smaller values. What happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Backward and central differences\n",
    " \n",
    "- Create new functions for the definition of the\n",
    "    - The backward difference (`dfdx_fd_bd`)\n",
    "    - The central difference (`dfdx_fd_cd`)\n",
    "    \n",
    "How does the derivative approximation change? Plot your results in the Python cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define function `dfdx_fd_bd` here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define function `dfdx_fd_cd` here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the error\n",
    "\n",
    "In the cell below you have the original definition of the function $f$, its analytical derivative, its forward difference derivative, and the error (the difference between the two derivatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.sin(2*x) + 2*np.cos(x)\n",
    "\n",
    "def dfdx(x):\n",
    "    return 2*np.cos(2*x) - 2*np.sin(x)\n",
    "\n",
    "def dfdx_fd(g, x0, dx):\n",
    "    return (g(x0+dx)-g(x0))/dx\n",
    "\n",
    "def err(x):\n",
    "    return dfdx(x) - dfdx_fd(f, x, 0.01)\n",
    "\n",
    "plt.plot(x, f(x), label='f')\n",
    "plt.plot(x, 100*err(x), label='err * 100')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Exploring the error\n",
    "\n",
    " - Compare error to the function itself. When is the error (its absolute value) largest? It may help to plot the derivative of $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Finding a \"good\" function\n",
    "\n",
    "- Choose another function $f$ and modify definitions of `f` and its analytically solved derivative `dfdx` above accordingly. What kind of function gives the smallest error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Backward and central difference errors\n",
    "\n",
    "- Calculate the error for your functions for the definition of the\n",
    "    - The backward difference (`dfdx_fd_bd`)\n",
    "    - The central difference (`dfdx_fd_cd`)\n",
    "    \n",
    "How does the error change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying finite differences to a physical problem\n",
    "\n",
    "If we know the analytical form of $f$, there is often little interest in approximating its derivative numerically. Instead, derivative approximations are used indirectly to approximate the values of $f$ itself. Let's see how this works in a simple example of a falling sphere.\n",
    "\n",
    "Consider a solid sphere sinking in a viscous fluid, with $\\rho_\\mathrm{sphere} > \\rho_\\mathrm{fluid}$. Gravity pulls the sphere downwards, causing a buoyancy force\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  F_\\mathrm{b} = V\\Delta\\rho g = V (\\rho_\\mathrm{sphere} - \\rho_\\mathrm{fluid}) g.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The viscous fluid resists the movement of the sphere downwards. The drag force is given by Stokes's law,\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  F_\\mathrm{d} = -6\\pi\\eta R v.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The sum of forces acting on the ball is then\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "  \\sum F &= m_\\mathrm{sphere} a \\newline\n",
    "  &= V\\rho_\\mathrm{sphere} a \\newline\n",
    "  &= F_\\mathrm{d} + F_\\mathrm{b} \\newline\n",
    "  &= -6\\pi\\eta R v + V (\\rho_\\mathrm{sphere} - \\rho_\\mathrm{fluid}) g.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Simplifying, and noting that $V = \\frac{4}{3}\\pi R^3$ and acceleration $a=\\frac{dv}{dt}$, gives \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  \\frac{dv}{dt} = -\\frac{9 \\eta v}{\\rho_\\mathrm{sphere} 2 R^2} + \\frac{(\\rho_\\mathrm{sphere} - \\rho_\\mathrm{fluid}) g}{\\rho_\\mathrm{sphere}}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "### A case without finite differences\n",
    "\n",
    "When the sphere has reached its terminal velocity, the acceleration is zero, so\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  dv/dt = 0 \\Rightarrow v = \\frac{2}{9}\\frac{\\Delta \\rho R^2 g}{\\eta}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "In this case we're able to directly calculate the terminal velocity. This can be directly converted to a Python function, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vel_term_stokes(rhosphere, rhofluid, radius, viscosity):\n",
    "    \"\"\"Returns the terminal velocity of a solid sphere sinking in a viscous fluid\"\"\"\n",
    "    return (2.0/9.0)*(rhosphere-rhofluid)*radius*radius*9.81 / viscosity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, for a marble with a radius of 2 cm sinking in honey we find the terminal velocity is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_term_stokes(2800, 1300, 0.02, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A case with finite differences\n",
    "\n",
    "If we again consider our general case for the sinking ball velocity, \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  \\frac{dv}{dt} = -\\frac{9 \\eta v}{\\rho_\\mathrm{sphere} 2 R^2} + \\frac{(\\rho_\\mathrm{sphere} - \\rho_\\mathrm{fluid}) g}{\\rho_\\mathrm{sphere}},\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "we could solve the problem by integrating both sides of the expression for acceleration. However, as an example, we will solve this numerically.\n",
    "\n",
    "To apply finite differences, we replace all derivatives with their finite approximations at time $t_0$. In this case,\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  \\frac{dv}{dt}\\Big\\rvert_{t=t_0} \\approx \\frac{v(t_0+\\Delta t) - v(t_0)}{\\Delta t}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Inserting this into the previous formula gives\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  \\frac{v(t_0+\\Delta t) - v(t_0)}{\\Delta t} = -\\frac{9 \\eta v(t_0)}{\\rho_\\mathrm{sphere} 2 R^2} + \\frac{(\\rho_\\mathrm{sphere} - \\rho_\\mathrm{fluid})g}{\\rho_\\mathrm{sphere}}.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Note that on the right hand side $v$ has been replaced by $v(t_0)$.\n",
    "\n",
    "In other words, if we know velocity at some time $t_0$ (i.e., $v(t_0)$), we can calculate the velocity after time $\\Delta t$ has elapsed: \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  v(t_0 + \\Delta t) = \\left(-\\frac{9 \\eta v(t_0)}{\\rho_\\mathrm{sphere} 2 \\pi R^2} + \\frac{(\\rho_\\mathrm{sphere} - \\rho_\\mathrm{fluid})g}{\\rho_\\mathrm{sphere}}\\right) \\Delta t + v(t_0)\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Let's write this as a python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vel_next(vel_prev, dt, rhosphere, rhofluid, radius, viscosity):\n",
    "    \"\"\"Returns the velocity of a solid sphere sinking in a viscous fluid\"\"\"\n",
    "    return (-9*viscosity*vel_prev / (rhosphere*2*radius*radius) + (rhosphere-rhofluid)*9.81/rhosphere)*dt + vel_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.0001\n",
    "v0 = 0.0\n",
    "v1 = vel_next(v0, dt, 2800, 1300, 0.02, 250)\n",
    "v2 = vel_next(v1, dt, 2800, 1300, 0.02, 250)\n",
    "v3 = vel_next(v2, dt, 2800, 1300, 0.02, 250)\n",
    "v4 = vel_next(v3, dt, 2800, 1300, 0.02, 250)\n",
    "v5 = vel_next(v4, dt, 2800, 1300, 0.02, 250)\n",
    "v6 = vel_next(v5, dt, 2800, 1300, 0.02, 250)\n",
    "v7 = vel_next(v6, dt, 2800, 1300, 0.02, 250)\n",
    "v1, v2, v3, v4, v5, v6, v7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this more useful, we can automate the calculation of the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.0001   # time step size\n",
    "v0 = 0.0      # initial condition\n",
    "nt = 50       # num of time steps to calculate\n",
    "\n",
    "v = np.zeros(nt)   # stores calculated velocities\n",
    "t = np.zeros(nt)   # stores total time in seconds\n",
    "\n",
    "v[0] = v0\n",
    "t[0] = 0.0\n",
    "\n",
    "for it in range(1,nt):\n",
    "    v[it] = vel_next(v[it-1], dt, 2800, 1300, 0.02, 250)\n",
    "    t[it] = t[it-1] + dt\n",
    "    \n",
    "plt.plot(t, v, '.-')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Velocity at time {t[-1]} s is {v[-1]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Dropping the ball\n",
    "\n",
    "- Use the code above to investigate what happens if the ball is being dropped from an elevation just slightly above the surface of the fluid. How do you need to modify the code?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Explicit and implicit solutions\n",
    "\n",
    "- Go back to the finite differences approximation of the equation above and replace $v(t_0)$ on the right hand side by $v(t_0 + \\Delta t)$. Rearrange the equation so that you have an expression for $v(t_0 + \\Delta t) = \\ldots$. \n",
    "    - Implement a function `vel_next_implicit`, similar to `vel_next` that calculates the velocity at next time step, but uses this modified expression.\n",
    "    - Copy and modify the code above so that you create a storage for both velocity values calculated using `vel_next` and `vel_next_implicit`, and plot the outcome on top of each other. Vary the value of `dt` and see what happens.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement `vel_next_implicit` here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approximation (`vel_next`) is the forward difference approximation. `vel_next_implicit` is the backward difference approximation. When applied to functions of time, these are also called *explicit* and *implicit* approximations."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
